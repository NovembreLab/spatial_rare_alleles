{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93bef005-cf73-47f1-981b-33915dab0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831403ac-38e1-40b8-a97d-14216b0c77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_syn = 1308.0216666666665\n",
    "len_mis = 2616.043333333333\n",
    "len_lof = 167.616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bb2a1e-27e9-4d4c-899d-61e90cec64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_kept_syn = 32320/247378\n",
    "prop_kept_mis = 32320/505963\n",
    "prop_kept_lof = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bcc5e9-70c6-4dc1-8337-94a7ad7ef314",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AVERAGE SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14cdac37-9997-40ec-b52c-d8ce25fa3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonymous\n",
      "170.89337073897704\n",
      "missense\n",
      "167.10810974979066\n",
      "lof\n",
      "167.616\n"
     ]
    }
   ],
   "source": [
    "nbins = 13\n",
    "n=10000\n",
    "sfs_unif = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_lof_uniformgeo_nSIR10000_nSIRreps10.SIRsfs', sep=' ')\n",
    "sfs_unif_grouped = sfs_unif.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "sfs_unif_avg = sfs_unif_grouped['mean']\n",
    "\n",
    "log_bins = np.logspace(np.log10(1), np.log10(n/2), num=nbins)\n",
    "log_bins = np.unique(np.round(log_bins))  \n",
    "\n",
    "log_bins = log_bins[log_bins <= 100][:-1]  \n",
    "log_bins = np.append(log_bins, [100, np.inf])  \n",
    "\n",
    "\n",
    "bin_centers = np.sqrt(log_bins[:-1] * log_bins[1:])\n",
    "bin_centers[-1] = 100 \n",
    "\n",
    "vartypes = ['synonymous', 'missense', 'lof']\n",
    "centers_geo = ['centerE16N4', 'centerE9N9', 'centerE6N4']\n",
    "w_list_geo = ['50000', '100000', '150000']\n",
    "labs_geo = ['A', 'B', 'C', 'D']\n",
    "\n",
    "centers_pca = ['centerX19Y4']\n",
    "w_list_pca = [0.0015, 0.0025, 0.005]\n",
    "labs_pca = ['E', 'F', 'G', 'H']\n",
    "\n",
    "\n",
    "sfs_data = []\n",
    "for k, vt in enumerate(vartypes):\n",
    "    print(vt)\n",
    "    if vt=='synonymous':\n",
    "        scale_factor = len_syn*prop_kept_syn # also divide by prop kept\n",
    "    elif vt=='missense':\n",
    "        scale_factor = len_mis*prop_kept_mis # also divide by prop kept\n",
    "    elif vt=='lof':\n",
    "        scale_factor = len_lof\n",
    "    print(scale_factor)\n",
    "    \n",
    "    # Process PCA data\n",
    "    sfs_unif_pca = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_uniformpca_nSIR10000_nSIRreps10.SIRsfs', sep=' ')\n",
    "    sfs_unif_pca_grouped = sfs_unif_pca.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "    sfs_unif_pca_avg = sfs_unif_pca_grouped['mean']/scale_factor\n",
    "    sfs_unif_pca_std = sfs_unif_pca_grouped['std']/scale_factor\n",
    "    \n",
    "    sfs_unif_pca_binned, _ = np.histogram(sfs_unif_pca_avg.index, bins=log_bins, weights=sfs_unif_pca_avg.values)\n",
    "    std_unif_pca_binned, _ = np.histogram(sfs_unif_pca_avg.index, bins=log_bins, weights=sfs_unif_pca_std.values)\n",
    "\n",
    "    for i in range(len(bin_centers)):\n",
    "        sfs_data.append([vt, \"H\", bin_centers[i], sfs_unif_pca_binned[i], std_unif_pca_binned[i]])  \n",
    "    \n",
    "    for j, w in enumerate(w_list_pca):\n",
    "        all_sfs_avg = []\n",
    "        all_sfs_std = []\n",
    "\n",
    "        for center in centers_pca:\n",
    "            sfs = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_{center}pca{w}_nSIR10000_nSIRreps10.SIRsfs', delimiter=' ')\n",
    "            sfs_avg_grouped = sfs.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "            all_sfs_avg.append(sfs_avg_grouped['mean']/scale_factor)\n",
    "            all_sfs_std.append(sfs_avg_grouped['std']/scale_factor)\n",
    "\n",
    "\n",
    "        sfs_avg_final = pd.concat(all_sfs_avg, axis=1).values\n",
    "        sfs_avg_forindex = pd.concat(all_sfs_avg, axis=1)\n",
    "        sfs_std_final = pd.concat(all_sfs_std, axis=1).values\n",
    "        sfs_forindex = sfs_avg_forindex.mean(axis=1)\n",
    "        sfs_avg_binned, _ = np.histogram(sfs_forindex.index, \n",
    "                                          bins=log_bins,\n",
    "                                          weights=sfs_avg_final.flatten())\n",
    "        std_gaussian_binned, _ = np.histogram(sfs_forindex.index,\n",
    "                                               bins=log_bins,\n",
    "                                               weights=sfs_std_final.flatten())\n",
    "        for i in range(len(bin_centers)):\n",
    "            sfs_data.append([vt, labs_pca[j], bin_centers[i], sfs_avg_binned[i], std_gaussian_binned[i]])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # Load and process uniform data for geo\n",
    "    sfs_unif_geo = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_uniformgeo_nSIR10000_nSIRreps10.SIRsfs', sep=' ')\n",
    "    sfs_unif_geo_grouped = sfs_unif_geo.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "    sfs_unif_geo_avg = sfs_unif_geo_grouped['mean']/scale_factor\n",
    "    sfs_unif_geo_std = sfs_unif_geo_grouped['std']/scale_factor\n",
    "\n",
    "    # Binning for uniform data (geo)\n",
    "    sfs_unif_geo_binned, _ = np.histogram(sfs_unif_geo_avg.index, bins=log_bins, weights=sfs_unif_geo_avg.values)\n",
    "    std_unif_geo_binned, _ = np.histogram(sfs_unif_geo_avg.index, bins=log_bins, weights=sfs_unif_geo_std.values)\n",
    "    for i in range(len(bin_centers)):\n",
    "        sfs_data.append([vt, \"D\", bin_centers[i], sfs_unif_geo_binned[i], std_unif_geo_binned[i]])\n",
    "\n",
    "    # Process Gaussian data for geo\n",
    "    for j, w in enumerate(w_list_geo):\n",
    "        all_sfs_avg = []\n",
    "        all_sfs_std = []\n",
    "\n",
    "        for center in centers_geo:\n",
    "            sfs = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_{center}geo{w}_nSIR10000_nSIRreps10.SIRsfs', delimiter=' ')\n",
    "            sfs_avg_grouped = sfs.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "            all_sfs_avg.append(sfs_avg_grouped['mean']/scale_factor)\n",
    "            all_sfs_std.append(sfs_avg_grouped['std']/scale_factor)\n",
    "        \n",
    "        combined_sfs_avg = pd.concat(all_sfs_avg, axis=1)\n",
    "        combined_sfs_std = pd.concat(all_sfs_std, axis=1)\n",
    "        sfs_avg_final = combined_sfs_avg.mean(axis=1)\n",
    "        sfs_std_final = combined_sfs_std.std(axis=1)\n",
    "\n",
    "        sfs_avg_binned, _ = np.histogram(sfs_avg_final.index, bins=log_bins, weights=sfs_avg_final.values)\n",
    "        std_gaussian_binned, _ = np.histogram(sfs_avg_final.index, bins=log_bins, weights=sfs_std_final.values)\n",
    "        for i in range(len(bin_centers)):\n",
    "            sfs_data.append([vt, labs_geo[j], bin_centers[i], sfs_avg_binned[i], std_gaussian_binned[i]])\n",
    "\n",
    "        \n",
    "\n",
    "sfs_df = pd.DataFrame(sfs_data, columns=['Variant_Type', 'Panel', 'Bin_Center', 'Binned_SFS', 'Binned_Std'])\n",
    "sfs_df.to_csv(\"sfs_binned_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcc7c3-7aea-4ac8-9eaa-c74575a613b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RATIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7897023a-00f5-4d90-9b8a-ed73163cc353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonymous\n",
      "170.89337073897704\n",
      "missense\n",
      "167.10810974979066\n",
      "lof\n",
      "167.616\n"
     ]
    }
   ],
   "source": [
    "nbins = 13\n",
    "n=10000\n",
    "sfs_unif = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_lof_uniformgeo_nSIR10000_nSIRreps10.SIRsfs', sep=' ')\n",
    "sfs_unif_grouped = sfs_unif.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "sfs_unif_avg = sfs_unif_grouped['mean']\n",
    "\n",
    "log_bins = np.logspace(np.log10(1), np.log10(n/2), num=nbins)\n",
    "log_bins = np.unique(np.round(log_bins))  \n",
    "\n",
    "log_bins = log_bins[log_bins <= 100][:-1]  \n",
    "log_bins = np.append(log_bins, [100, np.inf])  \n",
    "\n",
    "\n",
    "bin_centers = np.sqrt(log_bins[:-1] * log_bins[1:])\n",
    "bin_centers[-1] = 100 \n",
    "\n",
    "vartypes = ['synonymous', 'missense', 'lof']\n",
    "centers_geo = ['centerE16N4', 'centerE9N9', 'centerE6N4']\n",
    "w_list_geo = ['50000', '100000', '150000']\n",
    "labs_geo = ['A', 'B', 'C', 'D']\n",
    "\n",
    "centers_pca = ['centerX19Y4']\n",
    "w_list_pca = [0.0015, 0.0025, 0.005]\n",
    "labs_pca = ['E', 'F', 'G', 'H']\n",
    "\n",
    "\n",
    "sfs_data = []\n",
    "for k, vt in enumerate(vartypes):\n",
    "    print(vt)\n",
    "    if vt=='synonymous':\n",
    "        scale_factor = len_syn*prop_kept_syn # also divide by prop kept\n",
    "    elif vt=='missense':\n",
    "        scale_factor = len_mis*prop_kept_mis # also divide by prop kept\n",
    "    elif vt=='lof':\n",
    "        scale_factor = len_lof\n",
    "    print(scale_factor)\n",
    "    \n",
    "    # Process PCA data\n",
    "    sfs_unif_pca = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_uniformpca_nSIR10000_nSIRreps10.SIRsfs', sep=' ')\n",
    "    for rep in np.arange(1,11):\n",
    "        sfs_unif_pca_rep = sfs_unif_pca[sfs_unif_pca['SIR_REP']==rep]#.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "        sfs_unif_pca_rep['COUNT_SITES'] = sfs_unif_pca_rep['COUNT_SITES']/scale_factor\n",
    "    \n",
    "        sfs_unif_pca_binned, _ = np.histogram(sfs_unif_pca_rep['OBS_N'], bins=log_bins, weights=sfs_unif_pca_rep['COUNT_SITES'])\n",
    "        \n",
    "\n",
    "        for i in range(len(bin_centers)):\n",
    "            sfs_data.append([vt, \"H\", rep, 'uniform', bin_centers[i], sfs_unif_pca_binned[i]])  \n",
    "    \n",
    "        for j, w in enumerate(w_list_pca):\n",
    "            all_sfs_avg = []\n",
    "            all_sfs_std = []\n",
    "    \n",
    "            for center in centers_pca:\n",
    "                sfs = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_{center}pca{w}_nSIR10000_nSIRreps10.SIRsfs', delimiter=' ')\n",
    "                sfs_rep = sfs[sfs['SIR_REP']==rep]\n",
    "                sfs_rep['COUNT_SITES']=sfs_rep['COUNT_SITES']/scale_factor\n",
    "                sfs_binned, _ = np.histogram(sfs_rep['OBS_N'],bins=log_bins,weights=sfs_rep['COUNT_SITES'])\n",
    "\n",
    "                for i in range(len(bin_centers)):\n",
    "                    sfs_data.append([vt, labs_pca[j], rep, center, bin_centers[i], sfs_binned[i]])  \n",
    "\n",
    "    # Process geo data\n",
    "    sfs_unif_geo = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_uniformgeo_nSIR10000_nSIRreps10.SIRsfs', sep=' ')\n",
    "    for rep in np.arange(1,11):\n",
    "        sfs_unif_geo_rep = sfs_unif_geo[sfs_unif_geo['SIR_REP']==rep]#.groupby('OBS_N')['COUNT_SITES'].agg(['mean', 'std'])\n",
    "        sfs_unif_geo_rep['COUNT_SITES'] = sfs_unif_geo_rep['COUNT_SITES']/scale_factor\n",
    "    \n",
    "        sfs_unif_geo_binned, _ = np.histogram(sfs_unif_geo_rep['OBS_N'], bins=log_bins, weights=sfs_unif_geo_rep['COUNT_SITES'])\n",
    "        \n",
    "\n",
    "        for i in range(len(bin_centers)):\n",
    "            sfs_data.append([vt, \"D\", rep, 'uniform', bin_centers[i], sfs_unif_geo_binned[i]])  \n",
    "    \n",
    "        for j, w in enumerate(w_list_geo):\n",
    "            all_sfs_avg = []\n",
    "            all_sfs_std = []\n",
    "    \n",
    "            for center in centers_geo:\n",
    "                sfs = pd.read_csv(f'../empirical/subsampling_SIR_v20250127/results/sfs/chr1_{vt}_{center}geo{w}_nSIR10000_nSIRreps10.SIRsfs', delimiter=' ')\n",
    "                sfs_rep = sfs[sfs['SIR_REP']==rep]\n",
    "                sfs_rep['COUNT_SITES']=sfs_rep['COUNT_SITES']/scale_factor\n",
    "                sfs_binned, _ = np.histogram(sfs_rep['OBS_N'],bins=log_bins,weights=sfs_rep['COUNT_SITES'])\n",
    "\n",
    "                for i in range(len(bin_centers)):\n",
    "                    sfs_data.append([vt, labs_geo[j], rep, center, bin_centers[i], sfs_binned[i]])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "02e79a71-7e35-43ce-a8f4-bcf699c1c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_df_rep = pd.DataFrame(sfs_data,columns=['Variant Type','Panel','Rep','center','bin center', 'sfs_binned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1226fa57-aa18-4ece-98ee-65a698b6a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sfs_df_rep\n",
    "df_A = df[df['Panel']=='A']\n",
    "df_D = df[df['Panel']=='D']\n",
    "df_ratio = pd.merge(df_A, df_D, on=['Rep', 'bin center','Variant Type'], suffixes=('_A', '_D'))\n",
    "df_ratio['ratio'] = df_ratio['sfs_binned_A'] / df_ratio['sfs_binned_D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "879672af-74db-4fe0-a84e-7098711e15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_grouped = df_ratio.groupby(['Variant Type', 'bin center']).agg(\n",
    "    ratio=('ratio', 'mean'),\n",
    "    stdev=('ratio', 'std')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67a7f535-2de8-4625-b2b8-72bcfe68c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_grouped.to_csv('ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "928903ee-29a9-4296-98d4-daf7d029a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sfs_df_rep\n",
    "df_E = df[df['Panel']=='E']\n",
    "df_H = df[df['Panel']=='H']\n",
    "df_ratio = pd.merge(df_E, df_H, on=['Rep', 'bin center','Variant Type'], suffixes=('_E', '_H'))\n",
    "df_ratio['ratio'] = df_ratio['sfs_binned_E'] / df_ratio['sfs_binned_H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "51f9633a-91c8-4b6b-8855-4ccf9d02055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_grouped = df_ratio.groupby(['Variant Type', 'bin center']).agg(\n",
    "    ratio=('ratio', 'mean'),\n",
    "    stdev=('ratio', 'std')\n",
    ").reset_index()\n",
    "df_ratio_grouped.to_csv('ratios_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b5dba6e-fa99-4bc4-adcd-0cb7c64c6d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variant Type</th>\n",
       "      <th>bin center</th>\n",
       "      <th>ratio</th>\n",
       "      <th>stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lof</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.871410</td>\n",
       "      <td>0.020613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lof</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.820234</td>\n",
       "      <td>0.065244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lof</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.855524</td>\n",
       "      <td>0.072503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lof</td>\n",
       "      <td>11.661904</td>\n",
       "      <td>0.760761</td>\n",
       "      <td>0.086532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lof</td>\n",
       "      <td>24.392622</td>\n",
       "      <td>0.685131</td>\n",
       "      <td>0.085319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lof</td>\n",
       "      <td>59.160798</td>\n",
       "      <td>0.615239</td>\n",
       "      <td>0.057704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lof</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.793529</td>\n",
       "      <td>0.034099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>missense</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.845347</td>\n",
       "      <td>0.020035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>missense</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.861208</td>\n",
       "      <td>0.056515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>missense</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.810716</td>\n",
       "      <td>0.039695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>missense</td>\n",
       "      <td>11.661904</td>\n",
       "      <td>0.798831</td>\n",
       "      <td>0.037607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>missense</td>\n",
       "      <td>24.392622</td>\n",
       "      <td>0.645176</td>\n",
       "      <td>0.045191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>missense</td>\n",
       "      <td>59.160798</td>\n",
       "      <td>0.729249</td>\n",
       "      <td>0.033269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>missense</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.779277</td>\n",
       "      <td>0.011630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.814147</td>\n",
       "      <td>0.014092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.784761</td>\n",
       "      <td>0.037649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.776811</td>\n",
       "      <td>0.027091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>11.661904</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.020506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>24.392622</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.066491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>59.160798</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.019717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>synonymous</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.764528</td>\n",
       "      <td>0.007102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variant Type  bin center     ratio     stdev\n",
       "0           lof    1.414214  0.871410  0.020613\n",
       "1           lof    2.828427  0.820234  0.065244\n",
       "2           lof    5.656854  0.855524  0.072503\n",
       "3           lof   11.661904  0.760761  0.086532\n",
       "4           lof   24.392622  0.685131  0.085319\n",
       "5           lof   59.160798  0.615239  0.057704\n",
       "6           lof  100.000000  0.793529  0.034099\n",
       "7      missense    1.414214  0.845347  0.020035\n",
       "8      missense    2.828427  0.861208  0.056515\n",
       "9      missense    5.656854  0.810716  0.039695\n",
       "10     missense   11.661904  0.798831  0.037607\n",
       "11     missense   24.392622  0.645176  0.045191\n",
       "12     missense   59.160798  0.729249  0.033269\n",
       "13     missense  100.000000  0.779277  0.011630\n",
       "14   synonymous    1.414214  0.814147  0.014092\n",
       "15   synonymous    2.828427  0.784761  0.037649\n",
       "16   synonymous    5.656854  0.776811  0.027091\n",
       "17   synonymous   11.661904  0.772794  0.020506\n",
       "18   synonymous   24.392622  0.872903  0.066491\n",
       "19   synonymous   59.160798  0.626263  0.019717\n",
       "20   synonymous  100.000000  0.764528  0.007102"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratio_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
