#!python3

import pandas as pd
import numpy as np
import itertools


### --------- Configuration Information ---------- ###
configfile: "config.yml"

### --------- Set Up Targets --------- ###

seeds = range(1, 11) #21
chroms = range(1,23)
TARGETS = []
scenarios = config["UKBB"]["scenarios"]
for seed in seeds:
    for s in scenarios:
        for c in chroms:
            #TARGETS.append(
            #    f"results/sfs_files/merged_{s}_seed{seed}_n10000.sfs.tsv.gz",
            #)
            TARGETS.append(
                f"results/sum_stats/{s}_n10000_all.tsv",
            )
            TARGETS.append(
                f"results/sum_stats/{s}_n10000_LOF.tsv",
            )
            TARGETS.append(
                f"results/sfs/{s}_n10000_all.tsv",
            )
            TARGETS.append(
                f"results/sfs/{s}_n10000_LOF.tsv",
            )
#            TARGETS.append(
#                f"data/frq/chr{c}_wholedataset.frq",
#            )
#            TARGETS.append(
#                f"data/frq/chr{c}_within1epsilon_pca_all.frq.strat",
#            )
#            TARGETS.append(
#                f"data/frq/chr{c}_notwithin1epsilon_pca_all.frq.strat",
#            )
#            TARGETS.append(
#                f"data/frq/chr{c}_within5epsilon_geo_all.frq.strat",
#            )
#            TARGETS.append(
#                   f"data/frq/chr{c}_notwithin5epsilon_geo_all.frq.strat",
#            )

TARGETS.append("metadata/metadata_cleaned_wes_with_IS.csv")

# Just get the unique targets for the pipeline if possible.
TARGETS = np.unique(TARGETS).tolist()

rule all:
    input:
        TARGETS,

rule download_metadata:
    input:
    output:
        meta_file = "metadata/participant_metadata_all.csv",
        wes_ids = "metadata/wes_ids.txt"
    shell:
        "bash scripts/metadata.sh"

rule clean_metadata:
    input:
        meta_file = "metadata/participant_metadata_all.csv",
        wes_ids = "metadata/wes_ids.txt",
        pcs = "metadata/ukb_pca_plink2.eigenvec", # see PCA directory,
        coding10 = "metadata/codings/coding10.tsv", # from UKB
        coding100420 = "metadata/codings/coding100420.tsv", # from UKB
    output: 
        meta_clean = "metadata/metadata_cleaned_wes.csv"
    params:
        eps_pca = 0.0001,
        eps_geo = 10000,
    script:
        "scripts/clean_metadata.py"

rule importance_weights:
    input:
        "metadata/metadata_cleaned_wes.csv"
    output:
        "metadata/metadata_cleaned_wes_with_IS.csv"
    script:
        "scripts/importance_weights.py"

rule generate_fam_files:
    input:
        meta_clean = "metadata/metadata_cleaned_wes.csv"
    output: 
        fam_file="data/id_lists/{scenario}_seed{seed}_n{n}.tsv",
    params:
        numsamp=lambda wildcards: int(wildcards.n),
        label=lambda wildcards: wildcards.scenario,
        seed=lambda wildcards: int(wildcards.seed), 
       
    script:
        "scripts/gen_fam_files.py"
        
### NOTE: after this step, upload the fam files to directory maggie_pipeline_vF and cd into this directory

rule plink_frq:
    input:
        fam_file="data/id_lists/{scenario}_seed{seed}_n{n}.tsv",
    output:
        frq_file="data/frq/chr{chrom}_{scenario}_seed{seed}_n{n}.frq.strat"
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -iin={wildcards.scenario}_seed{wildcards.seed}_n{wildcards.n}.tsv \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --keep {wildcards.scenario}_seed{wildcards.seed}_n{wildcards.n}.tsv --freq --within {wildcards.scenario}_seed{wildcards.seed}_n{wildcards.n}.tsv --out chr{wildcards.chrom}_{wildcards.scenario}_seed{wildcards.seed}_n{wildcards.n}'
        dx download chr{wildcards.chrom}_{wildcards.scenario}_seed{wildcards.seed}_n{wildcards.n}.frq.strat
        mv chr{wildcards.chrom}_{wildcards.scenario}_seed{wildcards.seed}_n{wildcards.n}.frq.strat data/frq
        """

rule plink_frq_wholedataset:
    input:
    output:
        frq_file="data/frq/chr{chrom}_wholedataset.frq",
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --freq --out chr{wildcards.chrom}_wholedataset'
        dx download chr{wildcards.chrom}_wholedataset.frq
        mv chr{wildcards.chrom}_wholedataset.frq data/frq
        """

#rule plink_frq_wholedataset:
#    input:
#    output:
#        frq_file="data/frq/chr{chrom}_wholedataset.frq",
#    shell:
#        """
#        dx run app-swiss-army-knife -y --wait \
#            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ r$
#            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ r$
#            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ r$
#            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --freq --out chr{wildcards.chrom}_wholedataset'
#        dx download chr{wildcards.chrom}_wholedataset.frq
#        mv chr{wildcards.chrom}_wholedataset.frq data/frq
#        """

# note - see scripts directory for script which generates these fam files, also need to be uploaded to dnanexus
rule plink_frq_within1epsilon_pca_all:
    input:
        fam_file="data/id_lists/within_1epsilon_pca_all.tsv",
    output:
        frq_file="data/frq/chr{chrom}_within1epsilon_pca_all.frq.strat"
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -iin=within_1epsilon_pca_all.tsv \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --keep within_1epsilon_pca_all.tsv --freq --within within_1epsilon_pca_all.tsv --out chr{wildcards.chrom}_within1epsilon_pca_all'
        dx download chr{wildcards.chrom}_within1epsilon_pca_all.frq.strat
        mv chr{wildcards.chrom}_within1epsilon_pca_all.frq.strat data/frq
        """

rule plink_frq_notwithin1epsilon_pca_all:
    input:
        fam_file="data/id_lists/notwithin_1epsilon_pca_all.tsv",
    output:
        frq_file="data/frq/chr{chrom}_notwithin1epsilon_pca_all.frq.strat"
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -iin=notwithin_1epsilon_pca_all.tsv \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --keep notwithin_1epsilon_pca_all.tsv --freq --within notwithin_1epsilon_pca_all.tsv --out chr{wildcards.chrom}_notwithin1epsilon_pca_all'
        dx download chr{wildcards.chrom}_notwithin1epsilon_pca_all.frq.strat
        mv chr{wildcards.chrom}_notwithin1epsilon_pca_all.frq.strat data/frq
        """

rule plink_frq_within5epsilon_geo_all:
    input:
        fam_file="data/id_lists/within_5epsilon_geo_all.tsv",
    output:
        frq_file="data/frq/chr{chrom}_within5epsilon_geo_all.frq.strat"
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -iin=within_5epsilon_geo_all.tsv \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --keep within_5epsilon_geo_all.tsv --freq --within within_5epsilon_geo_all.tsv --out chr{wildcards.chrom}_within5epsilon_geo_all'
        dx download chr{wildcards.chrom}_within5epsilon_geo_all.frq.strat
        mv chr{wildcards.chrom}_within5epsilon_geo_all.frq.strat data/frq 
        """

rule plink_frq_notwithin5epsilon_geo_all:
    input:
        fam_file="data/id_lists/notwithin_5epsilon_geo_all.tsv",
    output:
        frq_file="data/frq/chr{chrom}_notwithin5epsilon_geo_all.frq.strat"
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -iin=notwithin_5epsilon_geo_all.tsv \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --keep notwithin_5epsilon_geo_all.tsv --freq --within notwithin_5epsilon_geo_all.tsv --out chr{wildcards.chrom}_notwithin5epsilon_geo_all'
        dx download chr{wildcards.chrom}_notwithin5epsilon_geo_all.frq.strat
        mv chr{wildcards.chrom}_notwithin5epsilon_geo_all.frq.strat data/frq
        """
        
rule format_tables_UKB_exomes:
    input:
        ukb_jsfs="data/frq/chr{chrom}_{scenario}_seed{seed}_n{n}.frq.strat",
        script="scripts/format_data_UKB.R",
        meta="metadata/ukb23158_500k_OQFE.annotations.txt"
    output:
        formatted_sfs="results/sfs_files/chr{chrom}_{scenario}_seed{seed}_n{n}.sfs.formatted.tsv.gz",
    run:
        shell("Rscript {input.script} {input.ukb_jsfs} {output.formatted_sfs} {input.meta}")

rule concat_join_sfs_UKB:
    input:
        expand(
            "results/sfs_files/chr{chrom}_{{scenario}}_seed{{seed}}_n{{n}}.sfs.formatted.tsv.gz",
            chrom=chroms,
        ),
    output:
        "results/sfs_files/merged_{scenario}_seed{seed}_n{n}.sfs.tsv.gz",
    shell:
        "zcat {input} | awk 'NR > 1 && /^Annot/ {{ next }} 1' | gzip > {output}"

rule sum_stats:
    input:
        expand(
            "results/sfs_files/merged_{{scenario}}_seed{seed}_n{{n}}.sfs.tsv.gz",
            seed=seeds,
        ),
    output:
        sum_stats_file="results/sum_stats/{scenario}_n{n}_{sfstype}.tsv",
    params:
        nsamp=lambda wildcards: int(wildcards.n),
        label=lambda wildcards: wildcards.scenario,
        type=lambda wildcards: wildcards.sfstype,
    script:
        "scripts/sum_stats.py"


rule sfs:
    input:
        expand(
            "results/sfs_files/merged_{{scenario}}_seed{seed}_n{{n}}.sfs.tsv.gz",
            seed=seeds,
        ),
    output:
        sum_stats_file="results/sfs/{scenario}_n{n}_{sfstype}.tsv",
    params:
        nsamp=lambda wildcards: int(wildcards.n),
        label=lambda wildcards: wildcards.scenario,
        type=lambda wildcards: wildcards.sfstype,
    script:
        "scripts/sfs.py"
