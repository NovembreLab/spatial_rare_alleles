#!python3

import pandas as pd
import numpy as np
import itertools
from hashlib import blake2b


### --------- Set Up Targets --------- ###

seeds = range(1, 2) #21
chroms = range(1,23)
TARGETS = []
groups = ['whitebritish']
n_vals = ['1000','3000','10000','50000','100000','300000']
numiter_list = [0]
type_list = ['all','lof']
for seed in seeds:
    for g in groups:
        for n in n_vals:
            for i in numiter_list:
                for t in type_list:
                    TARGETS.append(
                        f"results/sfs/group{g}_nsamp{n}_numiter{i}_{t}.tsv",
                    )
                    TARGETS.append(
                        f"results/sum_stats/group{g}_nsamp{n}_numiter{i}_{t}.tsv",
                    )
            
TARGETS = np.unique(TARGETS).tolist()

rule all:
    input:
        expand("results/sfs/group{g}_nsamp{n}_{t}.tsv",g=groups,n=n_vals,t=type_list),
        expand("results/sum_stats/group{g}_nsamp{n}_{t}.tsv",g=groups,n=n_vals,t=type_list),
 
### --------- Functions --------- ###

def wildcards2seed(group,n,numiter) -> int:
    filename="data/id_lists/group"+str(group)+"_nsamp"+str(n)+"_numiter"+str(numiter)+".tsv"
    h = blake2b(filename.encode(),digest_size=4)
    return int.from_bytes(h.digest(),"big")

### --------- Download Metadata --------- ###

rule download_metadata:
    input:
    output:
       "data/metadata/wes_ids_all.txt",
       "data/metadata/participant_metadata_all.csv",        
    shell:
        """
        bash scripts/metadata.sh
        """

rule filter_metadata:
    input:
        wes="data/metadata/wes_ids_all.txt",
        metadata_all="data/metadata/participant_metadata_all.csv",
    output:
        metadata_filtered="data/metadata/participant_metadata_wes.csv",
    shell:
        """
        awk -F',' 'NR==FNR{{a[$1]; next}} $1 in a' {input.wes} {input.metadata_all} > {output.metadata_filtered}.temp
        awk 'NR==1{{header=$0}} NR>1{{print header; exit}}' {input.metadata_all} > {output.metadata_filtered}
        tail -n +2 {output.metadata_filtered}.temp >> {output.metadata_filtered}
        rm {output.metadata_filtered}.temp
        """        
rule generate_fam_file:
    input:
        metadata_filtered="data/metadata/participant_metadata_wes.csv",
    output: 
        fam_file="data/id_lists/group{group}_nsamp{n}_numiter{numiter}.tsv",
    params:
        numsamp=lambda wildcards: int(wildcards.n),
        label=lambda wildcards: wildcards.group,
        seed=lambda wildcards: wildcards2seed(wildcards.group,wildcards.n,wildcards.numiter)
    script:
        "scripts/gen_fam.py"
        
### NOTE: after this step, upload the fam files to directory popgrowth and cd into this directory

rule plink_frq:
    input:
        fam_file="data/id_lists/group{group}_nsamp{n}_numiter{numiter}.tsv",
    output:
        frq_file="data/frq/chr{chrom}_group{group}_nsamp{n}_numiter{numiter}.frq.strat"
    shell:
        """
        dx run app-swiss-army-knife -y --wait \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bed \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.bim \
            -iin=Rare\ Variants\ in\ Space:/Bulk/Exome\ sequences/Population\ level\ exome\ OQFE\ variants,\ PLINK\ format\ -\ final\ release/ukb23158_c{wildcards.chrom}_b0_v1.fam \
            -iin=group{wildcards.group}_nsamp{wildcards.n}_numiter{wildcards.numiter}.tsv \
            -icmd='plink --bfile ukb23158_c{wildcards.chrom}_b0_v1 --keep group{wildcards.group}_nsamp{wildcards.n}_numiter{wildcards.numiter}.tsv --freq --within group{wildcards.group}_nsamp{wildcards.n}_numiter{wildcards.numiter}.tsv --out chr{wildcards.chrom}_group{wildcards.group}_nsamp{wildcards.n}_numiter{wildcards.numiter}'
        dx download chr{wildcards.chrom}_group{wildcards.group}_nsamp{wildcards.n}_numiter{wildcards.numiter}.frq.strat
        mv chr{wildcards.chrom}_group{wildcards.group}_nsamp{wildcards.n}_numiter{wildcards.numiter}.frq.strat data/frq
        """

rule format_tables_UKB_exomes:
    input:
        ukb_jsfs="data/frq/chr{chrom}_group{group}_nsamp{n}_numiter{numiter}.frq.strat",
        script="scripts/format_data_UKB.R",
        meta="data/metadata/ukb23158_500k_OQFE.annotations.txt"
    output:
        formatted_sfs="results/sfs_files/chr{chrom}_group{group}_nsamp{n}_numiter{numiter}.sfs.formatted.tsv.gz",
    run:
        shell("Rscript {input.script} {input.ukb_jsfs} {output.formatted_sfs} {input.meta}")

rule concat_join_sfs_UKB:
    input:
        expand(
            "results/sfs_files/chr{chrom}_group{{group}}_nsamp{{n}}_numiter{{numiter}}.sfs.formatted.tsv.gz",
            chrom=chroms,
        ),
    output:
        "results/sfs_files/merged_group{group}_nsamp{n}_numiter{numiter}.sfs.tsv.gz",
    shell:
        "zcat {input} | awk 'NR > 1 && /^Annot/ {{ next }} 1' | gzip > {output}"

rule sum_stats:
    input:
        expand(
            "results/sfs_files/merged_group{{group}}_nsamp{{n}}_numiter{numiter}.sfs.tsv.gz",
            numiter=numiter_list,
        ),
    output:
        sum_stats_file="results/sum_stats/group{group}_nsamp{n}_{type}.tsv",
    params:
        nsamp=lambda wildcards: int(wildcards.n),
        group=lambda wildcards: wildcards.group,
        type=lambda wildcards: wildcards.type,
    script:
        "scripts/sum_stats.py"


rule sfs:
    input:
        expand(
            "results/sfs_files/merged_group{{group}}_nsamp{{n}}_numiter{numiter}.sfs.tsv.gz",
            numiter=numiter_list,
        ),
    output:
        sum_stats_file="results/sfs/group{group}_nsamp{n}_{type}.tsv",
    params:
        nsamp=lambda wildcards: int(wildcards.n),
        group=lambda wildcards: wildcards.group,
        type=lambda wildcards: wildcards.type,
    script:
        "scripts/sfs.py"
